{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwmrTG/fr/jlXzmiI83cKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 미니배치 적용 MLP"],"metadata":{"id":"7CzStJxAXXuZ"}},{"cell_type":"markdown","source":["# 레이어 1개(128), relu, size = 1개"],"metadata":{"id":"aVsgayYdidTU"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","class MLP:\n","    def __init__(self, n_input, n_hidden1, n_output, size):\n","        self.n_input = n_input\n","        self.n_hidden1 = n_hidden1\n","        self.n_output = n_output\n","        self.size= size\n","        \n","        # 가중치와 편향 초기화\n","        #self.w1 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_input, self.n_hidden1))\n","        self.w1 = np.random.randn(self.n_input, self.n_hidden1)/np.sqrt(self.n_input/2)\n","        self.b1 = np.zeros((1, self.n_hidden1))\n","        #self.w2 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_hidden1, self.n_hidden2))\n","        self.w2 = np.random.randn(self.n_hidden1, self.n_output )/np.sqrt(self.n_hidden1/2)\n","        self.b2 = np.zeros((1, self.n_output))\n","        \n","\n","    def ReLU(self, z):\n","          return np.maximum(0, z)\n","\n","    def softmax(self, z):\n","          z_max = np.max(z)\n","          exp_z = np.exp(z-z_max)\n","          y = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n","          #print(y)\n","          return y\n","\n","    def feed(self, x, w, b):\n","          f = np.dot(x, w) + b\n","          return f\n","    \n","    def cross_entropy(self, y, o):\n","          loss = -np.mean(y * np.log(o)) #cross entropy\n","          #loss = np.square(np.subtract(o_1, y)).mean()\n","          return loss\n","\n","    def feedforward(self, X, y):\n","\n","          input_x = self.feed(X, self.w1, self.b1)\n","          input_x = self.ReLU(input_x)\n","\n","          osum = self.feed(input_x, self.w2, self.b2)\n","          o_1 = self.softmax(osum)\n","                  \n","          return o_1, input_x\n","\n","    def batch (self, X, o, loss, w):\n","\n","          update_w = np.dot(o.T,loss) / self.size #이전 레이어에 전달하여 기울기를 계산\n","          update_b = np.sum(loss, axis=0, keepdims=True) / self.size #(o_1 - y)에서 샘플에 대한 오차를 모두 더한다.\n","          pass_loss = np.dot(loss, w.T) #출력층에서 역전파되는 오차를 이전 은닉층에 전달하기 위한 값\n","          pass_loss[o <= 0] = 0                 #이전 은닉층에서의 가중치 업데이트에 사용\n","          pass_loss = pass_loss * (o > 0) #활성화(relu) 함수 미분과 곱하여 두번째 은닉층에서의 오차값을 구함\n","\n","          return update_w, update_b, pass_loss\n","\n","    def backpropagation(self, X, y, epochs, lr):\n","\n","        batches =X_train.shape[0] // self.size\n","\n","        for epoch in range(epochs):\n","\n","            #섞어서 하나 뽑기\n","            shuffle = np.random.permutation(len(X))\n","            X = X[shuffle]\n","            y = y[shuffle]\n","\n","            for batch in range(batches) :\n","              start = batch * self.size\n","              end = (batch+1) * self.size\n","\n","              X_batch = X[start:end]\n","              y_batch = y[start:end]\n","\n","              o_1, input_x= self.feedforward(X_batch,y_batch) #feedfoward한 값을 받아온다.\n","              loss = self.cross_entropy(y_batch, o_1)\n","              sgd_loss = (o_1 - y_batch)\n","\n","              update_w2, update_b2, pass_loss =self.batch(X_batch, input_x, sgd_loss, self.w2)\n","              update_w1 = np.dot(X_batch.T, pass_loss) / self.size\n","              update_b1 = np.sum(pass_loss, axis=0, keepdims=True) / self.size\n","\n","              # 가중치와 편향 업데이트\n","\n","              self.w2 -= lr * update_w2\n","              self.b2 -= lr * update_b2\n","              self.w1 -= lr * update_w1\n","              self.b1 -= lr * update_b1\n","            \n","            \n","           # 손실 출력\n","            if epoch % 10== 0:\n","                print(f'Epoch {epoch}, Loss {loss:.4f}') \n","\n","          \n","    def predict(self, X, y):\n","          o_1, input_x= self.feedforward(X, y)\n","          y_pred = np.argmax(o_1, axis=1)\n","          return y_pred\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# X 데이터 정규화\n","minmaxscalar = MinMaxScaler()\n","X = minmaxscalar.fit_transform(X)\n","#X = (X - X.mean(axis=0)) / X.std(axis=0)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n","\n","# 레이블을 one-hot encoding으로 변환\n","lb = LabelBinarizer()\n","y_train = lb.fit_transform(y_train)\n","y_test = lb.transform(y_test)\n","\n","# MLP 모델 생성\n","mlp = MLP(n_input=4, n_hidden1=128, n_output=3, size=1)\n","\n","# 모델 학습\n","mlp.backpropagation(X_train, y_train, epochs=100, lr=0.1)\n","\n","# 모델 테스트\n","y_pred = mlp.predict(X_test, y_test)\n","\n","# 정확도 계산\n","y_test_true = np.argmax(y_test, axis=1)\n","accuracy = np.mean(y_pred == y_test_true)\n","print(f'Test Accuracy: {accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvmzMbIDiMYR","executionInfo":{"status":"ok","timestamp":1683708502785,"user_tz":-540,"elapsed":4530,"user":{"displayName":"박민희","userId":"02008349284485949886"}},"outputId":"1060f5c3-6ba7-4124-a38d-ba34e73a925a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss 0.1184\n","Epoch 10, Loss 0.0063\n","Epoch 20, Loss 0.0006\n","Epoch 30, Loss 0.0016\n","Epoch 40, Loss 0.0056\n","Epoch 50, Loss 0.0000\n","Epoch 60, Loss 0.0046\n","Epoch 70, Loss 0.2224\n","Epoch 80, Loss 0.0000\n","Epoch 90, Loss 0.0000\n","Test Accuracy: 0.9833\n"]}]},{"cell_type":"markdown","source":["# 레이어 2개, relu, size =1"],"metadata":{"id":"zm2LW4GTaElh"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","class MLP:\n","    def __init__(self, n_input, n_hidden1, n_hidden2, n_output, size):\n","        self.n_input = n_input\n","        self.n_hidden1 = n_hidden1\n","        self.n_hidden2 = n_hidden2\n","        self.n_output = n_output\n","        self.size = size\n","        \n","        # 가중치와 편향 초기화\n","        #self.w1 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_input, self.n_hidden1))\n","        self.w1 = np.random.randn(self.n_input, self.n_hidden1)/np.sqrt(self.n_input/2)\n","        self.b1 = np.zeros((1, self.n_hidden1))\n","        #self.w2 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_hidden1, self.n_hidden2))\n","        self.w2 = np.random.randn(self.n_hidden1, self.n_hidden2 )/np.sqrt(self.n_hidden1/2)\n","        self.b2 = np.zeros((1, self.n_hidden2))\n","        #self.w3 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_hidden2, self.n_output))\n","        self.w3 = np.random.randn(self.n_hidden2, self.n_output )/np.sqrt(self.n_hidden2/2)\n","        self.b3 = np.zeros((1, self.n_output))\n","\n","    def ReLU(self, z):\n","          return np.maximum(0, z)\n","\n","    def softmax(self, z):\n","          z_max = np.max(z)\n","          exp_z = np.exp(z-z_max)\n","          y = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n","          #print(y)\n","          return y\n","\n","    def feed(self, x, w, b):\n","          f = np.dot(x, w) + b\n","          return f\n","    \n","    def cross_entropy(self, y, o):\n","          loss = -np.mean(y * np.log(o)) #cross entropy\n","          #loss = np.square(np.subtract(o_1, y)).mean()\n","          return loss\n","\n","    def feedforward(self, X, y):\n","\n","          input_x = self.feed(X, self.w1, self.b1)\n","          input_x = self.ReLU(input_x)\n","\n","          zsum = self.feed(input_x, self.w2, self.b2)\n","          z_1 = self.ReLU(zsum)\n","\n","          osum = self.feed(z_1, self.w3, self.b3)\n","          o_1 = self.softmax(osum)\n","                  \n","          return o_1, input_x, z_1\n","\n","    def batch (self, X, o, loss, w):\n","\n","          update_w = np.dot(o.T,loss) / self.size #이전 레이어에 전달하여 기울기를 계산\n","          update_b = np.sum(loss, axis=0, keepdims=True) / self.size #(o_1 - y)에서 샘플에 대한 오차를 모두 더한다.\n","          pass_loss = np.dot(loss, w.T) #출력층에서 역전파되는 오차를 이전 은닉층에 전달하기 위한 값\n","          pass_loss[o <= 0] = 0                 #이전 은닉층에서의 가중치 업데이트에 사용\n","          pass_loss = pass_loss * (o > 0) #활성화(relu) 함수 미분과 곱하여 두번째 은닉층에서의 오차값을 구함\n","\n","          return update_w, update_b, pass_loss\n","\n","\n","    def backpropagtion(self, X, y, epochs, lr):\n","\n","        batches = X.shape[0]// self.size\n","\n","        for epoch in range(epochs):\n","\n","            #섞어서 하나 뽑기\n","            shuffle = np.random.permutation(len(X))\n","            X = X[shuffle]\n","            y = y[shuffle]\n","\n","            for batch in range(batches) :\n","              start_idx = batch * self.size\n","              end_idx = (batch+1) * self.size\n","\n","              X_batch = X[start_idx:end_idx]\n","              y_batch = y[start_idx:end_idx]\n","\n","              o_1, input_x, z_1 = self.feedforward(X_batch,y_batch) #feedfoward한 값을 받아온다.\n","              loss = self.cross_entropy(y_batch, o_1)\n","              sgd_loss = (o_1 - y_batch)\n","\n","              update_w3, update_b3, pass_loss2 =self.batch( X_batch, z_1, sgd_loss, self.w3)\n","              update_w2, update_b2, pass_loss =self.batch(X_batch, input_x, pass_loss2, self.w2)\n","              update_w1 = np.dot(X_batch.T, pass_loss) / self.size\n","              update_b1 = np.sum(pass_loss, axis=0, keepdims=True) / self.size\n","\n","\n","              # 가중치와 편향 업데이트\n","              self.w3 -= lr * update_w3\n","              self.b3 -= lr * update_b3\n","              self.w2 -= lr * update_w2\n","              self.b2 -= lr * update_b2\n","              self.w1 -= lr * update_w1\n","              self.b1 -= lr * update_b1\n","            \n","            \n","\n","            # 손실 출력\n","            if epoch % 100 == 0:\n","                print(f'Epoch {epoch}, Loss {loss:.4f}') \n","            # if loss < 0.000001:\n","            #     break     \n","          \n","    def predict(self, X, y):\n","          o_1, input_x, z_1 = self.feedforward(X, y)\n","          y_pred = np.argmax(o_1, axis=1)\n","          return y_pred\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","\n","# X 데이터 정규화\n","minmaxscalar = MinMaxScaler()\n","X = minmaxscalar.fit_transform(X)\n","#X = (X - X.mean(axis=0)) / X.std(axis=0)\n","\n","#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n","\n","\n","# 레이블을 one-hot encoding으로 변환\n","lb = LabelBinarizer()\n","y_train = lb.fit_transform(y_train)\n","y_test = lb.transform(y_test)\n","\n","\n","# MLP 모델 생성\n","mlp = MLP(n_input=X_train.shape[1], n_hidden1=256, n_hidden2= 128, n_output=3, size = 1)\n","\n","# 모델 학습\n","mlp.backpropagtion(X_train, y_train, epochs=1000, lr=0.01)\n","\n","# 모델 테스트\n","y_pred = mlp.predict(X_test, y_test)\n","\n","# 정확도 계산\n","y_test_true = np.argmax(y_test, axis=1)\n","accuracy = np.mean(y_pred == y_test_true)\n","print(f'Test Accuracy: {accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NO8X9uhifFo0","executionInfo":{"status":"ok","timestamp":1683288214107,"user_tz":-540,"elapsed":44197,"user":{"displayName":"박민희","userId":"02008349284485949886"}},"outputId":"7da78ad8-0295-4085-efec-534c6ab3a137"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss 0.0324\n","Epoch 100, Loss 0.0000\n","Epoch 200, Loss 0.0002\n","Epoch 300, Loss 0.0113\n","Epoch 400, Loss 0.0475\n","Epoch 500, Loss 0.0000\n","Epoch 600, Loss 0.0000\n","Epoch 700, Loss 0.0001\n","Epoch 800, Loss 0.0000\n","Epoch 900, Loss 0.0000\n","Test Accuracy: 0.9833\n"]}]},{"cell_type":"markdown","source":["# 레이어 2개, relu, size=5"],"metadata":{"id":"jXjER13jXKcQ"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","class MLP:\n","    def __init__(self, n_input, n_hidden1, n_hidden2, n_output, size):\n","        self.n_input = n_input\n","        self.n_hidden1 = n_hidden1\n","        self.n_hidden2 = n_hidden2\n","        self.n_output = n_output\n","        self.size= size\n","        \n","        # 가중치와 편향 초기화\n","        #self.w1 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_input, self.n_hidden1))\n","        self.w1 = np.random.randn(self.n_input, self.n_hidden1)/np.sqrt(self.n_input/2)\n","        self.b1 = np.zeros((1, self.n_hidden1))\n","        #self.w2 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_hidden1, self.n_hidden2))\n","        self.w2 = np.random.randn(self.n_hidden1, self.n_hidden2 )/np.sqrt(self.n_hidden1/2)\n","        self.b2 = np.zeros((1, self.n_hidden2))\n","        #self.w3 = np.random.uniform(low =-1.0, high = 1.0, size=(self.n_hidden2, self.n_output))\n","        self.w3 = np.random.randn(self.n_hidden2, self.n_output )/np.sqrt(self.n_hidden2/2)\n","        self.b3 = np.zeros((1, self.n_output))\n","\n","    def ReLU(self, z):\n","          return np.maximum(0, z)\n","\n","    def softmax(self, z):\n","          z_max = np.max(z)\n","          exp_z = np.exp(z-z_max)\n","          y = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n","          #print(y)\n","          return y\n","\n","    def feed(self, x, w, b):\n","          f = np.dot(x, w) + b\n","          return f\n","    \n","    def cross_entropy(self, y, o):\n","          loss = -np.mean(y * np.log(o)) #cross entropy\n","          #loss = np.square(np.subtract(o_1, y)).mean()\n","          return loss\n","\n","    def feedforward(self, X, y):\n","\n","          input_x = self.feed(X, self.w1, self.b1)\n","          input_x = self.ReLU(input_x)\n","\n","          zsum = self.feed(input_x, self.w2, self.b2)\n","          z_1 = self.ReLU(zsum)\n","\n","          osum = self.feed(z_1, self.w3, self.b3)\n","          o_1 = self.softmax(osum)\n","                  \n","          return o_1, input_x, z_1\n","\n","    def batch (self, X, o, loss, w):\n","\n","          update_w = np.dot(o.T,loss) / self.size #이전 레이어에 전달하여 기울기를 계산\n","          update_b = np.sum(loss, axis=0, keepdims=True) / self.size #(o_1 - y)에서 샘플에 대한 오차를 모두 더한다.\n","          pass_loss = np.dot(loss, w.T) #출력층에서 역전파되는 오차를 이전 은닉층에 전달하기 위한 값\n","          pass_loss[o <= 0] = 0                 #이전 은닉층에서의 가중치 업데이트에 사용\n","          pass_loss = pass_loss * (o > 0) #활성화(relu) 함수 미분과 곱하여 두번째 은닉층에서의 오차값을 구함\n","\n","          return update_w, update_b, pass_loss\n","\n","    def backpropagation(self, X, y, epochs, lr):\n","\n","        batches =X_train.shape[0] // self.size\n","\n","        for epoch in range(epochs):\n","\n","            #섞어서 하나 뽑기\n","            shuffle = np.random.permutation(len(X))\n","            X = X[shuffle]\n","            y = y[shuffle]\n","\n","            for batch in range(batches) :\n","              start = batch * self.size\n","              end = (batch+1) * self.size\n","\n","              X_batch = X[start:end]\n","              y_batch = y[start:end]\n","\n","              o_1, input_x, z_1 = self.feedforward(X_batch,y_batch) #feedfoward한 값을 받아온다.\n","              loss = self.cross_entropy(y_batch, o_1)\n","              sgd_loss = (o_1 - y_batch)\n","\n","              update_w3, update_b3, pass_loss2 =self.batch( X_batch, z_1, sgd_loss, self.w3)\n","              update_w2, update_b2, pass_loss =self.batch(X_batch, input_x, pass_loss2, self.w2)\n","              update_w1 = np.dot(X_batch.T, pass_loss) / self.size\n","              update_b1 = np.sum(pass_loss, axis=0, keepdims=True) / self.size\n","\n","              # 가중치와 편향 업데이트\n","              self.w3 -= lr * update_w3\n","              self.b3 -= lr * update_b3\n","              self.w2 -= lr * update_w2\n","              self.b2 -= lr * update_b2\n","              self.w1 -= lr * update_w1\n","              self.b1 -= lr * update_b1\n","            \n","            \n","           # 손실 출력\n","            if epoch % 100 == 0:\n","                print(f'Epoch {epoch}, Loss {loss:.4f}') \n","            if loss < 0.000001:\n","                break     \n","          \n","    def predict(self, X, y):\n","          o_1, input_x, z_1= self.feedforward(X, y)\n","          y_pred = np.argmax(o_1, axis=1)\n","          return y_pred\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# X 데이터 정규화\n","minmaxscalar = MinMaxScaler()\n","X = minmaxscalar.fit_transform(X)\n","#X = (X - X.mean(axis=0)) / X.std(axis=0)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n","\n","# 레이블을 one-hot encoding으로 변환\n","lb = LabelBinarizer()\n","y_train = lb.fit_transform(y_train)\n","y_test = lb.transform(y_test)\n","\n","# MLP 모델 생성\n","mlp = MLP(n_input=4, n_hidden1=256, n_hidden2=128, n_output=3, size=5)\n","\n","# 모델 학습\n","mlp.backpropagation(X_train, y_train, epochs=1000, lr=0.01)\n","\n","# 모델 테스트\n","y_pred = mlp.predict(X_test, y_test)\n","\n","# 정확도 계산\n","y_test_true = np.argmax(y_test, axis=1)\n","accuracy = np.mean(y_pred == y_test_true)\n","print(f'Test Accuracy: {accuracy:.4f}')"],"metadata":{"id":"GeojdL5UXmLG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683283733339,"user_tz":-540,"elapsed":7975,"user":{"displayName":"박민희","userId":"02008349284485949886"}},"outputId":"6cfe5733-a401-4f67-d7d9-3012bcdb1a75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss 0.2455\n","Epoch 100, Loss 0.0574\n","Epoch 200, Loss 0.0847\n","Epoch 300, Loss 0.0392\n","Epoch 400, Loss 0.0420\n","Epoch 500, Loss 0.0011\n","Epoch 600, Loss 0.0002\n","Epoch 700, Loss 0.0007\n","Epoch 800, Loss 0.0289\n","Epoch 900, Loss 0.0000\n","Test Accuracy: 0.9833\n"]}]}]}